#ECON613 A2 Mengzhi Chen
#==================================================

#Set working directory
setwd("/Users/halcyonchan/Desktop/Econ613/A2/Data")
install.packages("data.table")
library(data.table)


#Exercise1============================================
#1.1==================================================
#Calculate the correlation between Y and X
#Read the file
datind2009 = fread("datind2009.csv")
install.packages("tidyverse")
library(tidyverse)
dat = datind2009 %>% drop_na(wage)
x = matrix(dat$age)
#Add one column of intercept
intercept = matrix(rep(1,20232))
X = cbind(intercept,x)
Y = matrix(dat$wage)
#Calculate the correlation
cor(x,Y,method=c("pearson","kendall","spearman"),use="complete.obs")
#The correlation coefficient is -0.1788512

#1.2==================================================
#Calculate the coefficients on this regression 
beta = solve(t(X)%*%X)%*%t(X)%*%Y
beta
#the coefficient of X: beta1 is -180.1765, and the intercept beta0 is 22075.1066

#1.3================================================
#Calculate the standard errors of beta
#Using the standard formulas of the OLS
Y_hat = X%*%beta
e = (Y-Y_hat)
s2 = t(e)%*%e/(length(Y)-2)
XX = solve(t(X)%*%X)
SE1 = sqrt(s2*XX[1,1]) #The standard error of coefficient of intercept is 357.8275
SE2 = sqrt(s2*XX[2,2]) #The standard error of coefficient of age is 6.968652
SE1
SE2

#Using bootstrap with 49 replications
SE1 = matrix(1:49)
SE2 = matrix(1:49)
for (i in 1:49) {
  deter1 = sample(1:length(x),length(x),replace=TRUE) #sample the number of data in original data
  dat_boot = dat[deter1,] #Choose the corresponding number of data
  independ = matrix(dat_boot$age) #Choose the corresponding independent variable 
  intercept = matrix(rep(1,length(independ)))
  independ1 = cbind(intercept,independ)
  depend = matrix(dat_boot$wage) #Choose the corresponding dependent variable 
  coef = solve(t(independ1)%*%independ1)%*%t(independ1)%*%depend #Use formula to compute the coefficients 
  #Calculate the standard error of intercept and coefficient 
  depend_hat = independ1%*%coef
  e = (depend-depend_hat)
  s2 = t(e)%*%e/(length(Y)-2)
  XX = solve(t(X)%*%X)
  SE1[i] = sqrt(s2*XX[1,1]) 
  SE2[i] = sqrt(s2*XX[2,2])
} 
SE1_boot49 = mean(SE1)
SE1_boot49 #The standard error of coefficient of intercept is 356.6284
SE2_boot49 = mean(SE2)
SE2_boot49 #The standard error of coefficient of age is 6.9453

#Using bootstrap with 499 replications. The model is the same as above.
SE1 = matrix(1:499)
SE2 = matrix(1:499)
for (i in 1:499) {
  deter1 = sample(1:length(x),length(x),replace=TRUE)
  dat_boot = dat[deter1,]
  independ = matrix(dat_boot$age)
  intercept = matrix(rep(1,length(independ)))
  independ1 = cbind(intercept,independ)
  depend = matrix(dat_boot$wage)
  coef = solve(t(independ1)%*%independ1)%*%t(independ1)%*%depend
  depend_hat = independ1%*%coef
  e = (depend-depend_hat)
  s2 = t(e)%*%e/(length(Y)-2)
  XX = solve(t(X)%*%X)
  SE1[i] = sqrt(s2*XX[1,1])
  SE2[i] = sqrt(s2*XX[2,2])
} 
SE1_boot49 = mean(SE1)
SE1_boot49 #The standard error of coefficient of intercept is 357.8577
SE2_boot49 = mean(SE2)
SE2_boot49 #The standard error of coefficient of age is 6.96924

#Comment on the difference between the two strategies
#The standard error generated by bootstrap with 499 replications is more precise than that with 49 replications, 
#because by repeating more times, the result will be more and more closer to the standard error calculated by OLS formulas.


#Exercise2============================================
#read the data from 2005 to 2018
datind2005 = fread("datind2005.csv",colClasses=c(idmen = "character",idind = "character"))
datind2006 = fread("datind2006.csv",colClasses=c(idmen = "character",idind = "character"))
datind2007 = fread("datind2007.csv",colClasses=c(idmen = "character",idind = "character"))
datind2008 = fread("datind2008.csv",colClasses=c(idmen = "character",idind = "character"))
datind2009 = fread("datind2009.csv",colClasses=c(idmen = "character",idind = "character"))
datind2010 = fread("datind2010.csv",colClasses=c(idmen = "character",idind = "character"))
datind2011 = fread("datind2011.csv",colClasses=c(idmen = "character",idind = "character"))
datind2012 = fread("datind2012.csv",colClasses=c(idmen = "character",idind = "character"))
datind2013 = fread("datind2013.csv",colClasses=c(idmen = "character",idind = "character"))
datind2014 = fread("datind2014.csv",colClasses=c(idmen = "character",idind = "character"))
datind2015 = fread("datind2015.csv",colClasses=c(idmen = "character",idind = "character"))
datind2016 = fread("datind2016.csv",colClasses=c(idmen = "character",idind = "character"))
datind2017 = fread("datind2017.csv",colClasses=c(idmen = "character",idind = "character"))
datind2018 = fread("datind2018.csv",colClasses=c(idmen = "character",idind = "character"))
# Use rbind() to append all these datasets
datind=rbind(datind2005,datind2006,datind2007,datind2008,datind2009,datind2010,datind2011,
             datind2012,datind2013,datind2014,datind2015,datind2016,datind2017,datind2018)

#2.1==================================================
#Create a categorical variable ag, which bins the age variables into the following groups: 
#“18-25”, “26- 30”, “31-35”, “36-40”,“41-45”, “46-50”,“51-55”, “56-60”, and “60+”.
datind[which(datind[,9]>=18 & datind[,9]<=25),"ag"] = "18-25"
datind[which(datind[,9]>=26 & datind[,9]<=30),"ag"] = "26-30"
datind[which(datind[,9]>=31 & datind[,9]<=35),"ag"] = "31-35"
datind[which(datind[,9]>=36 & datind[,9]<=40),"ag"] = "36-40"
datind[which(datind[,9]>=41 & datind[,9]<=45),"ag"] = "41-45"
datind[which(datind[,9]>=46 & datind[,9]<=50),"ag"] = "46-50"
datind[which(datind[,9]>=51 & datind[,9]<=55),"ag"] = "51-55"
datind[which(datind[,9]>=56 & datind[,9]<=60),"ag"] = "56-60"
datind[which(datind[,9]>60),"ag"] = "60+"
datind

#2.2==================================================
#Plot the wage of each age group across years. Is there a trend?
datind = datind %>% drop_na(ag)
datind = datind %>% drop_na(wage)
#Group the data according to year and age groups,and calculate the mean wage of each age group across years
datind_ag = aggregate(x=datind$wage,by=list(datind$year,datind$ag),FUN=mean)
#rename the columns
colnames(datind_ag)[1]="year"
colnames(datind_ag)[2]="age"
colnames(datind_ag)[3]="mean_wage"
datind_ag
#Plot the the wage of age group 18-25 across years
dat_ag1 = datind_ag[which(datind_ag[2]=="18-25"),]
ggplot(select(dat_ag1,year,mean_wage),aes(x=year,y=mean_wage))+geom_bar(stat = "identity")
#Plot the the wage of age group 26-30 across years
dat_ag2 = datind_ag[which(datind_ag[2]=="26-30"),]
ggplot(select(dat_ag2,year,mean_wage),aes(x=year,y=mean_wage))+geom_bar(stat = "identity")
#Plot the the wage of age group 31-35 across years
dat_ag3 = datind_ag[which(datind_ag[2]=="31-35"),]
ggplot(select(dat_ag3,year,mean_wage),aes(x=year,y=mean_wage))+geom_bar(stat = "identity")
#Plot the the wage of age group 36-40 across years
dat_ag3 = datind_ag[which(datind_ag[2]=="36-40"),]
ggplot(select(dat_ag3,year,mean_wage),aes(x=year,y=mean_wage))+geom_bar(stat = "identity")
#Plot the the wage of age group 41-45 across years
dat_ag4 = datind_ag[which(datind_ag[2]=="41-45"),]
ggplot(select(dat_ag4,year,mean_wage),aes(x=year,y=mean_wage))+geom_bar(stat = "identity")
#Plot the the wage of age group 46-50 across years
dat_ag5 = datind_ag[which(datind_ag[2]=="46-50"),]
ggplot(select(dat_ag5,year,mean_wage),aes(x=year,y=mean_wage))+geom_bar(stat = "identity")
#Plot the the wage of age group 51-55 across years
dat_ag6 = datind_ag[which(datind_ag[2]=="51-55"),]
ggplot(select(dat_ag6,year,mean_wage),aes(x=year,y=mean_wage))+geom_bar(stat = "identity")
#Plot the the wage of age group 56-60 across years
dat_ag7 = datind_ag[which(datind_ag[2]=="56-60"),]
ggplot(select(dat_ag7,year,mean_wage),aes(x=year,y=mean_wage))+geom_bar(stat = "identity")
#Plot the the wage of age group 60+ across years
dat_ag8 = datind_ag[which(datind_ag[2]=="60+"),]
ggplot(select(dat_ag8,year,mean_wage),aes(x=year,y=mean_wage))+geom_bar(stat = "identity")
#Trend:The salary of each age group increases through years, and the salary increases first and then decreases with age.

#2.3==================================================
#Consider Yit = βXit + γt + eit. After including a time fixed effect, how do the estimated coefficients change?
#install.packages("plm")
#library(plm)
datind=rbind(datind2005,datind2006,datind2007,datind2008,datind2009,datind2010,datind2011,
             datind2012,datind2013,datind2014,datind2015,datind2016,datind2017,datind2018)
#The regression without fixed effect
reg = lm(datind$wage~datind$age,datind)
reg$coefficients[2]
#Use plm and include a time fixed effect
reg1 = plm(datind$wage~datind$age,datind,index=c("year"),model="within")
reg1$coefficients[1]
#The estimated coefficient is -186.8793, which decreases from -182.4896 


#Exercise3============================================
#We are interested in the effect of age on labor market participation.
#We consider this problem using the data from 2007. Consider a probit model.
#3.1==================================================
#Exclude all individuals who are inactive
datind2007 = fread("datind2007.csv")
#Use which to exclude "inactive" individuals
dat2 = datind2007[which(datind2007$empstat!="Inactive"),]
dat2

#3.2==================================================
#Write a function that returns the likelihood of the probit of being employed
#You might want to write Xβ first. Then, calculate F(Xβ) and the log likelihood
#Remember, for the probit model, F(x) is the standard normal distribution function
probit = function(beta,x,y) {
  xbeta = beta[1] + beta[2]*x
  pr = pnorm(xbeta)
  pr[pr>0.999999] = 0.999999
  pr[pr<0.000001] = 0.000001
  like = y*log(pr) + (1-y)*log(1-pr)
  return(-sum(like,log=TRUE))
}
#Set the dependent and independent variables
dat2 = dat2 %>% mutate(employed = ifelse(dat2$empstat == "Employed",1,0))
#Use probit regression in R
reg2 = glm(dat2$employed~dat2$age,family = binomial(link = "probit"))
summary(reg2)
#Test whether the function is correct
test_beta = reg2$coefficients
test_beta #3.8291873(intercept)  -0.0678642(a) 
#Get the same result
probit(test_beta,dat2$age,dat2$employed) #6581.155
logLik(reg2) #-6582.155 (df=2)

#3.3==================================================
#Optimize the model and interpret the coefficients. You can use pre-programmed optimization packages
start1 = runif(2,min=-0.07,max=3.9)
probit(start1,dat2$age,dat2$employed) 
opt1 = optim(start1,fn=probit,method="BFGS",
             control=list(trace=6,REPORT=1,maxit=1000),x=dat2$age,y=dat2$employed,hessian=TRUE)
opt1$par
opt1$value
#Interpret the coefficient: Everything else is equal, if the age of the individual increases,
#the probability of his/her labor market participation will decrease.

#3.4==================================================
#Can you estimate the same model including wages as a deterxminant of labor market participation? Explain.
dat3 = dat2 %>% drop_na(wage)
probit2 = function(beta,x1,x2,y) {
  xbeta = beta[1] + beta[2]*x1+beta[3]*x2
  pr = pnorm(xbeta)
  pr[pr>0.999999] = 0.999999
  pr[pr<0.000001] = 0.000001
  like = y*log(pr) + (1-y)*log(1-pr)
  return(-sum(like,log=TRUE))
}
#Set the dependent and independent variables
a1 = dat3$age
a2 = dat3$wage
y1 = dat3$employed
#Use probit regression in R
reg3 = glm(y1~a1+a2,family = binomial(link = "probit"))
summary(reg3)
#Test whether the function is correct
test_beta = reg3$coefficients
test_beta 
probit2(test_beta,a1,a2,y1) #4636.991
logLik(reg3) #-4766.646
#I think I can't use the same model because the result from the function is different from the result by regression.
#The algorithm did not converge and fitted probabilities numerically 0 or 1 occurred.


#Exercise4============================================
#We are interested in the effect of age on labor market participation. 
#Use the pooled version of the data from 2005 to 2015. Additional controls include time-fixed effects.
#4.1==================================================
#Use the pooled version of the data from 2005 to 2015
datind2005 = fread("datind2005.csv",colClasses=c(idmen = "character",idind = "character"))
datind2006 = fread("datind2006.csv",colClasses=c(idmen = "character",idind = "character"))
datind2007 = fread("datind2007.csv",colClasses=c(idmen = "character",idind = "character"))
datind2008 = fread("datind2008.csv",colClasses=c(idmen = "character",idind = "character"))
datind2009 = fread("datind2009.csv",colClasses=c(idmen = "character",idind = "character"))
datind2010 = fread("datind2010.csv",colClasses=c(idmen = "character",idind = "character"))
datind2011 = fread("datind2011.csv",colClasses=c(idmen = "character",idind = "character"))
datind2012 = fread("datind2012.csv",colClasses=c(idmen = "character",idind = "character"))
datind2013 = fread("datind2013.csv",colClasses=c(idmen = "character",idind = "character"))
datind2014 = fread("datind2014.csv",colClasses=c(idmen = "character",idind = "character"))
datind2015 = fread("datind2015.csv",colClasses=c(idmen = "character",idind = "character"))
datind2=rbind(datind2005,datind2006,datind2007,datind2008,datind2009,datind2010,datind2011,
              datind2012,datind2013,datind2014,datind2015)
#Exclude all individuals who are inactive
dat4 = datind2[which(datind2$empstat!="Inactive"),]
dat4

#4.2==================================================
#Write and optimize the probit, logit, and the linear probability models
#Remember, for the logit model, F(x) is the logistic function exp(x)/(1+exp(x))
dat4 = dat4 %>% mutate(employed = ifelse(dat4$empstat == "Employed",1,0),
                       y05 = ifelse(dat4$year=="2005",1,0),
                       y06 = ifelse(dat4$year=="2006",1,0),
                       y07 = ifelse(dat4$year=="2007",1,0),
                       y08 = ifelse(dat4$year=="2008",1,0),
                       y09 = ifelse(dat4$year=="2009",1,0),
                       y10 = ifelse(dat4$year=="2010",1,0),
                       y11 = ifelse(dat4$year=="2011",1,0),
                       y12 = ifelse(dat4$year=="2012",1,0),
                       y13 = ifelse(dat4$year=="2013",1,0),
                       y14 = ifelse(dat4$year=="2014",1,0))
dat4

#Write the probit regression and fixed the effect of year by adding dummy variables for each year
probit3 = function(beta,x,y05,y06,y07,y08,y09,y10,y11,y12,y13,y14,y) {
  xbeta = beta[1]+beta[2]*x+beta[3]*y05+beta[4]*y06+beta[5]*y07+beta[6]*y08
  +beta[7]*y09+beta[8]*y10+beta[9]*y11+beta[10]*y12+beta[11]*y13+beta[12]*y14
  pr = pnorm(xbeta)
  pr[pr>0.999999] = 0.999999
  pr[pr<0.000001] = 0.000001
  like = y*log(pr) + (1-y)*log(1-pr)
  return(-sum(like))
}

reg4 = glm(dat4$employed~dat4$age+dat4$y05+dat4$y06+dat4$y07+dat4$y08+dat4$y09+
             dat4$y10+dat4$y11+dat4$y12+dat4$y13+dat4$y14,family = binomial(link = "probit"))
summary(reg4)
#Output the coefficient
beta = reg4$coefficients
beta
beta[2] #-0.06358962 (dat4$age) 

#Optimize the probit3 model
start_probit=runif(12,min=-0.064,max=1)
probit3(start_probit,dat4$age,dat4$y05,dat4$y06,dat4$y07,dat4$y08,dat4$y09,dat4$y10,
        dat4$y11,dat4$y12,dat4$y13,dat4$y14,dat4$employed) 
opt_probit = optim(start_probit,fn=probit3,method="BFGS",control=list(trace=6,REPORT=1,maxit=1000),
             x=dat4$age,y05=dat4$y05,y06=dat4$y06,y07=dat4$y07,y08=dat4$y08,y09=dat4$y09,y10=dat4$y10,
             y11=dat4$y11,y12=dat4$y12,y13=dat4$y13,y14=dat4$y14,y=dat4$employed,hessian=TRUE)
opt_probit$par[2]
opt_probit$value #The model is optimized with likelihood decreased


#Write the logit model and fixed the effect of year
logit = function(beta,x,y05,y06,y07,y08,y09,y10,y11,y12,y13,y14,y) {
  xbeta = beta[1]+beta[2]*x+beta[3]*y05+beta[4]*y06+beta[5]*y07+beta[6]*y08
  +beta[7]*y09+beta[8]*y10+beta[9]*y11+beta[10]*y12+beta[11]*y13+beta[12]*y14
  pr = exp(xbeta)/(1+exp(xbeta))
  pr[pr>0.999999] = 0.999999
  pr[pr<0.000001] = 0.000001
  like = y*log(pr) + (1-y)*log(1-pr)
  return(-sum(like,log=TRUE))
}

reg5 = glm(dat4$employed~dat4$age+dat4$y05+dat4$y06+dat4$y07+dat4$y08+dat4$y09+
             dat4$y10+dat4$y11+dat4$y12+dat4$y13+dat4$y14,family = binomial(link = "logit"))
summary(reg5)
#Output the coefficient
beta = reg5$coefficients
beta
beta[2] #-0.1241425 (dat4$age)

#Optimize the logit model
start_logit=runif(12,min=-0.13)
logit(reg5$coefficients,dat4$age,dat4$y05,dat4$y06,dat4$y07,dat4$y08,dat4$y09,dat4$y10,
      dat4$y11,dat4$y12,dat4$y13,dat4$y14,dat4$employed) 
opt_logit = optim(reg5$coefficients,fn=logit,method="BFGS",control=list(trace=6,REPORT=1,maxit=1000),
             x=dat4$age,y05=dat4$y05,y06=dat4$y06,y07=dat4$y07,y08=dat4$y08,y09=dat4$y09,y10=dat4$y10,
             y11=dat4$y11,y12=dat4$y12,y13=dat4$y13,y14=dat4$y14,y=dat4$employed,hessian=TRUE)
opt_logit$par[2] 
opt_logit$value #The model is optimized with likelihood decreased


#Write the linear probability model
linear = function(beta,x,y05,y06,y07,y08,y09,y10,y11,y12,y13,y14,y) {
  y_hat = beta[1]+beta[2]*x+beta[3]*y05+beta[4]*y06+beta[5]*y07+beta[6]*y08
  +beta[7]*y09+beta[8]*y10+beta[9]*y11+beta[10]*y12+beta[11]*y13+beta[12]*y14
  y_hat = as.numeric(y_hat)
  e = (y - y_hat)
  return(sum(e^2))
}

reg6= glm(dat4$employed~dat4$age+dat4$y05+dat4$y06+dat4$y07+dat4$y08+dat4$y09+
             dat4$y10+dat4$y11+dat4$y12+dat4$y13+dat4$y14)
summary(reg6)
#Output the coefficient
beta = reg6$coefficients
beta
beta[2] #-0.01846614 (dat4$age)

#Optimize the linear probability model
start_linear=runif(12,min=-0.02,max=1)
linear(beta,dat4$age,dat4$y05,dat4$y06,dat4$y07,dat4$y08,dat4$y09,dat4$y10,
       dat4$y11,dat4$y12,dat4$y13,dat4$y14,dat4$employed) 
opt_linear = optim(reg6$coefficients,fn=linear,method="BFGS",control=list(trace=6,REPORT=1,maxit=1000),
             x=dat4$age,y05=dat4$y05,y06=dat4$y06,y07=dat4$y07,y08=dat4$y08,y09=dat4$y09,y10=dat4$y10,
             y11=dat4$y11,y12=dat4$y12,y13=dat4$y13,y14=dat4$y14,y=dat4$employed,hessian=TRUE)
opt_linear$par[2] 
opt_linear$value #The model is optimized with likelihood decreased


#4.3==================================================
#Interpret and compare the estimated coefficients. How significant are they?
opt_probit$par[2] #The estimated coefficients -0.06359803
opt_logit$par[2] #The estimated coefficients in logit model is -0.1241426 
opt_linear$par[2] #The estimated coefficients in llinear probability model is -0.0184598
#The estimated coefficients in each model are all negative, which indicates that when everything else is equal, 
#the individual is less likely to participate in job with the increase of age.

#Compute the t statistics of estimator in probit model
probit_hessian = opt_probit$hessian[1:6,1:6]
t_probit = opt_probit$par[2]/sqrt(solve(probit_hessian)[2,2])
t_probit 
#Test the significant
qt(0.975,df=(nrow(dat4)-13)) #1.959976
#Since |t_probit| > 1.959976, the estimated coefficient is significant.

#Compute the t statistics of estimator in logit model
logit_hessian = opt_logit$hessian[1:6,1:6]
t_logit = opt_logit$par[2]/sqrt(solve(logit_hessian)[2,2])
t_logit 
#Since |t_logit| > 1.959976, the estimated coefficient is significant.

#Compute the t statistics of estimator in linear probability model
y_hat = opt_linear$par[1]+opt_linear$par[2]*dat4$age+opt_linear$par[3]*dat4$y05+opt_linear$par[4]*dat4$y06+
  opt_linear$par[5]*dat4$y07+opt_linear$par[6]*dat4$y08+opt_linear$par[7]*dat4$y09+opt_linear$par[8]*dat4$y10+
  opt_linear$par[9]*dat4$y11+opt_linear$par[10]*dat4$y12+opt_linear$par[11]*dat4$y13+opt_linear$par[12]*dat4$y14
e = (dat4$employed-y_hat)
s2 = t(e)%*%e/(nrow(dat4)-13)
X = cbind(rep(1,nrow(dat4)), dat4$age, dat4$y05,dat4$y06,dat4$y07,dat4$y08,dat4$y09,dat4$y10,
          dat4$y11,dat4$y12,dat4$y13,dat4$y14)
XX = solve(t(X)%*%X)
SE2_linear = sqrt(s2*XX[2,2])
SE2_linear
t_linear = opt_linear$par[2]/SE2_linear
t_linear 
#Test the significant
qt(0.975,df=(nrow(dat4)-13)) #1.959976
#Since |t_linear| > 1.959976, the estimated coefficient is significant.


#Exercise5 Marginal Effects
#5.1==================================================
#Compute the marginal effect of the previous probit and logit models
y_hat_probit = opt_probit$par[1]+opt_probit$par[2]*dat4$age+opt_probit$par[3]*dat4$y05+opt_probit$par[4]*dat4$y06+
  opt_probit$par[5]*dat4$y07+opt_probit$par[6]*dat4$y08+opt_probit$par[7]*dat4$y09+opt_probit$par[8]*dat4$y10+
  opt_probit$par[9]*dat4$y11+opt_probit$par[10]*dat4$y12+opt_probit$par[11]*dat4$y13+opt_probit$par[12]*dat4$y14
mar1 = mean(dnorm(y_hat_probit))
probit_margin = mar1*opt_probit$par
probit_margin[2]

y_hat_logit = opt_logit$par[1]+opt_logit$par[2]*dat4$age+opt_logit$par[3]*dat4$y05+opt_logit$par[4]*dat4$y06+
  opt_logit$par[5]*dat4$y07+opt_logit$par[6]*dat4$y08+opt_logit$par[7]*dat4$y09+opt_logit$par[8]*dat4$y10+
  opt_logit$par[9]*dat4$y11+opt_logit$par[10]*dat4$y12+opt_logit$par[11]*dat4$y13+opt_logit$par[12]*dat4$y14
mar2 = mean(dlogis(y_hat_logit))
logit_margin = mar2*opt_logit$par
logit_margin[2]

#5.2==================================================
#Construct the standard errors of the marginal effects. Hint: Boostrap may be the easiest way.
#Suppose we replicate 10 times for 12 coefficients
#Probit model
mat1 = matrix(data=0,nrow=10,ncol=12)
for (i in 1:10) {
  #Sample a new dataset from original data
  dat_boost1 = dat4[sample(1:nrow(dat4),nrow(dat4),replace=TRUE),]
  #Use the data sampled from orginal dataset, and optimize the probit model
  opt_sam_probit = optim(reg4$coefficients,fn=probit3,method="BFGS",control=list(trace=6,REPORT=1,maxit=1000),
        x=dat_boost1$age,y05=dat_boost1$y05,y06=dat_boost1$y06,y07=dat_boost1$y07,y08=dat_boost1$y08,
        y09=dat_boost1$y09,y10=dat_boost1$y10,y11=dat_boost1$y11,y12=dat_boost1$y12,y13=dat_boost1$y13,
        y14=dat_boost1$y14,y=dat_boost1$employed,hessian=TRUE)
  #The estimate value of probit model
  y_hat_probit2 = opt_sam_probit$par[1]+opt_sam_probit$par[2]*dat_boost1$age+opt_sam_probit$par[3]*dat_boost1$y05+
    opt_sam_probit$par[4]*dat_boost1$y06+opt_sam_probit$par[5]*dat_boost1$y07+opt_sam_probit$par[6]*dat_boost1$y08+
    opt_sam_probit$par[7]*dat_boost1$y09+opt_sam_probit$par[8]*dat_boost1$y10+opt_sam_probit$par[9]*dat_boost1$y11+
    opt_sam_probit$par[10]*dat_boost1$y12+opt_sam_probit$par[11]*dat_boost1$y13+opt_sam_probit$par[12]*dat_boost1$y14
  #Compute the marginal effect
  dist1 = mean(dnorm(y_hat_probit2))
  mat1[i,] = dist1*opt_sam_probit$par
}
#Standard error of marginal effect in probit model
se_probit = sd(mat1[,2])
se_probit

#Logit model
mat2 = matrix(data=0,nrow=10,ncol=12)
for (i in 1:10) {
  #Sample a new dataset from original data
  dat_boost2 = dat4[sample(1:nrow(dat4),nrow(dat4),replace=TRUE),]
  #Use the data sampled from orginal dataset, and optimize the logit model
  opt_sam_logit = optim(reg5$coefficients,fn=logit,method="BFGS",control=list(trace=6,REPORT=1,maxit=1000),
                         x=dat_boost2$age,y05=dat_boost2$y05,y06=dat_boost2$y06,y07=dat_boost2$y07,y08=dat_boost2$y08,
                         y09=dat_boost2$y09,y10=dat_boost2$y10,y11=dat_boost2$y11,y12=dat_boost2$y12,y13=dat_boost2$y13,
                         y14=dat_boost2$y14,y=dat_boost2$employed,hessian=TRUE)
  #The estimate value of logit model
  y_hat_logit2 = opt_sam_logit$par[1]+opt_sam_logit$par[2]*dat_boost1$age+opt_sam_logit$par[3]*dat_boost1$y05+
    opt_sam_logit$par[4]*dat_boost1$y06+opt_sam_logit$par[5]*dat_boost1$y07+opt_sam_logit$par[6]*dat_boost1$y08+
    opt_sam_logit$par[7]*dat_boost1$y09+opt_sam_logit$par[8]*dat_boost1$y10+opt_sam_logit$par[9]*dat_boost1$y11+
    opt_sam_logit$par[10]*dat_boost1$y12+opt_sam_logit$par[11]*dat_boost1$y13+opt_sam_logit$par[12]*dat_boost1$y14
  #Compute the marginal effect
  dist2 = mean(dlogis(y_hat_logit2))
  mat2[i,] = dist2*opt_sam_logit$par
}
#Standard error of marginal effect in probit model
se_logit = sd(mat2[,2])
se_logit



